---
title: "ReactorTwin"
date: 2026-02-10
description: "Surrogate digital twin for industrial chemical reactors using neural ODEs and physics-informed neural networks."
tags: ["pytorch", "neural-odes", "pinns", "chemical-engineering", "digital-twin"]
status: "active"
github: "https://github.com/ktubhyam/reactor-twin"
featured: true
---

ReactorTwin creates fast, accurate surrogate models of chemical reactors that run 1500x faster than traditional CFD simulations while preserving physical constraints. It bridges the gap between first-principles reactor modeling and data-driven machine learning.

## The Problem

Industrial chemical reactors are governed by coupled systems of ODEs describing mass balance, energy balance, and reaction kinetics. Traditional approaches for modeling them fall into two camps:

1. **First-principles CFD:** Accurate but computationally expensive — a single CSTR steady-state simulation can take minutes, and transient analysis hours. Too slow for real-time optimization or control.

2. **Empirical correlations:** Fast but brittle — tuned to specific operating windows and break down outside their calibration range. No physics guarantees.

ReactorTwin uses **neural ODEs** to learn the dynamics directly from process data, while physics-informed constraints ensure the predictions respect conservation laws even in extrapolation regimes.

## Architecture

```
Process Data (T, P, C_i, F)
    → Feature Engineering
        ├── Residence time τ = V/F
        ├── Damköhler number Da = k·τ
        └── Péclet number Pe = v·L/D
    → Neural ODE Encoder
        ├── Physics-constrained right-hand side f(z, t; θ)
        ├── Mass balance: Σ(C_i · F) = const
        └── Energy balance: dH/dt = Q̇ - Σ(r_j · ΔH_j)
    → Latent State z(t) ∈ ℝ^64
    → Decoder Heads
        ├── Concentration profiles C_i(t)
        ├── Temperature profile T(t)
        ├── Conversion X(t)
        └── Selectivity S_i(t)
```

### Neural ODE Core

The reactor dynamics are modeled as a learned ODE:

$$\frac{dz}{dt} = f_\theta(z, t, u)$$

where $z$ is the latent reactor state, $t$ is time, $u$ is the operating conditions (feed temperature, flow rate, catalyst loading), and $f_\theta$ is a neural network parameterizing the dynamics. Integration is performed via `torchdiffeq` with adaptive step-size Dormand-Prince (dopri5) or implicit Adams methods for stiff systems.

The key advantage over standard sequence models (LSTMs, Transformers) is that neural ODEs naturally handle:
- **Irregular time spacing** — process data arrives at non-uniform intervals
- **Continuous-time predictions** — query the model at any time point, not just observed timestamps
- **Conservation law enforcement** — structure the network to respect physical invariants

### Physics-Informed Constraints

Rather than treating physics as a soft penalty, ReactorTwin encodes constraints directly into the network architecture:

**Mass conservation:** The neural ODE right-hand side is structured so that the total mass flow is conserved:

$$\sum_i \frac{dC_i}{dt} \cdot V = F_\text{in} \cdot C_{i,\text{in}} - F_\text{out} \cdot C_i + \sum_j \nu_{ij} \cdot r_j \cdot V$$

This is enforced by parameterizing the reaction terms $r_j$ separately and computing concentration changes from stoichiometry, rather than predicting each $dC_i/dt$ independently.

**Energy conservation:** Temperature dynamics are constrained by the enthalpy balance — heat generation from reactions must equal heat removal plus accumulation.

**Thermodynamic consistency:** Equilibrium constants from Cantera provide upper bounds on conversion, preventing the model from predicting physically impossible yields.

### Reactor Types

ReactorTwin supports four standard reactor configurations:

| Reactor | Governing Equations | Key Parameters |
|---------|-------------------|----------------|
| **CSTR** | Well-mixed: $dC/dt = (C_\text{in} - C)/\tau - r(C, T)$ | Volume, $\tau$, heat transfer coefficient |
| **PFR** | Plug flow: $dC/dz = -r(C, T)/v$ | Length, diameter, velocity profile |
| **Batch** | Closed system: $dC/dt = -r(C, T)$ | Volume, initial conditions |
| **Semi-batch** | Time-varying feed: $d(VC)/dt = F_\text{in}C_\text{in} - rV$ | Feed rate schedule, volume change |

Each reactor type has a specialized ODE right-hand side template that the neural network fills in — learning the reaction kinetics and transport coefficients while the conservation structure is fixed.

## Training Pipeline

### Data Sources

1. **Simulated data** from Cantera + scipy.integrate for known reaction systems (A→B, A+B→C, etc.) with added measurement noise
2. **Process historian data** from DCS/SCADA systems (CSV/OPC-UA format)
3. **Experiment logs** with manual sampling points and lab analysis results

### Loss Function

$$\mathcal{L} = \underbrace{\|C_\text{pred} - C_\text{obs}\|^2}_\text{data fit} + \lambda_1 \underbrace{\|\text{mass imbalance}\|^2}_\text{conservation} + \lambda_2 \underbrace{\|T_\text{pred} - T_\text{obs}\|^2}_\text{energy fit} + \lambda_3 \underbrace{\mathcal{L}_\text{thermo}}_\text{equilibrium}$$

The thermodynamic loss $\mathcal{L}_\text{thermo}$ penalizes predictions that exceed equilibrium conversion for reversible reactions, using Gibbs free energy calculations from Cantera.

### Training Details

- **Optimizer:** AdamW with cosine annealing
- **Integration:** Adaptive dopri5 for non-stiff, implicit Adams for stiff kinetics
- **Adjoint method:** Memory-efficient backpropagation through the ODE solve via continuous adjoint sensitivity
- **Regularization:** Jacobian penalty on $f_\theta$ to prevent artificially stiff learned dynamics

## Monitoring Dashboard

A real-time web dashboard built with Next.js and D3.js provides:

- **Live reactor state:** Current temperature, pressure, concentrations updated every 5 seconds
- **Prediction overlay:** Neural ODE predictions vs. actual sensor readings with confidence bands
- **What-if analysis:** Drag sliders to change feed temperature, flow rate, or catalyst loading and see predicted steady-state shifts in real time
- **Anomaly detection:** Mahalanobis distance in the latent space $z(t)$ flags when the reactor drifts outside the training distribution
- **Historical replay:** Scrub through past operating data with model predictions overlaid

## Tech Stack

- **Core:** PyTorch + torchdiffeq for neural ODE integration
- **Thermodynamics:** Cantera for equilibrium calculations, species properties, and reaction mechanisms
- **Dashboard:** Next.js + D3.js + WebSocket for real-time visualization
- **Serving:** FastAPI + Docker for model inference endpoints
- **Data ingestion:** Apache Arrow / Parquet for time-series storage, OPC-UA client for DCS connectivity

## Performance

| Metric | CFD Simulation | ReactorTwin |
|--------|---------------|-------------|
| CSTR steady-state | 45s | 0.03s (1500x) |
| PFR concentration profile | 120s | 0.08s (1500x) |
| Batch trajectory (100 points) | 300s | 0.2s (1500x) |
| Parameter sweep (100 conditions) | 4.5 hours | 3s |

Accuracy on held-out test conditions (within training distribution): RMSE < 2% of steady-state values for concentration, < 1K for temperature.

## Related

- **Blog:** [Neural ODEs for Reactor Modeling](/blog/neural-odes-for-reactor-modeling) — detailed walkthrough of the neural ODE approach and training pipeline
- **Blog:** [The Spectral Inverse Problem](/blog/spectral-inverse-problem) — similar inverse-problem methodology applied to spectroscopy
- **Project:** [Spektron](/projects/spektron) — another physics-informed deep learning project for spectral data
