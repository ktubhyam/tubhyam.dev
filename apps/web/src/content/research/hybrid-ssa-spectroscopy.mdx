---
title: "Oscillatory State Space Models for Vibrational Spectroscopy: Benchmarking, Cross-Spectral Prediction, and Interpretability"
date: 2026-01-15
authors: ["Tubhyam Karthikeyan"]
venue: "Digital Discovery (RSC)"
status: "in-progress"
abstract: "We present the first evaluation of state-space models for vibrational spectroscopy. We benchmark five architectures — D-LinOSS, Mamba, Transformer, 1D CNN, and S4D — on masked spectral reconstruction using 130K DFT-computed IR and Raman spectra from QM9S. We introduce cross-spectral prediction (IR to Raman and vice versa) as a novel task with no prior work, and demonstrate that D-LinOSS transfer function analysis provides unique interpretability through learned spectral filter banks."
tags: ["deep-learning", "spectroscopy", "state-space-models", "benchmark"]
---

## Motivation

State-space models (SSMs) have driven breakthroughs in NLP and genomics, but scientific spectroscopy remains untouched. We argue that vibrational spectroscopy is a uniquely natural domain for SSMs: spectra are 1D signals arising from molecular vibrations (damped harmonic oscillators), and D-LinOSS — a 2nd-order oscillatory SSM — models exactly these dynamics. This is a **function-space argument**: D-LinOSS's basis functions (damped sinusoids) are a natural basis for vibrational spectra.

We present an honest empirical study evaluating whether this physics alignment translates to practical advantages. We benchmark D-LinOSS against four other architectures, introduce cross-spectral prediction as a genuinely novel task, and demonstrate that SSM transfer functions provide interpretability inaccessible to other architectures.

## Architecture

### Stage 1: Raw Spectral Embedding

Unlike vision transformers that tokenize images into patches, Spektron preserves the full spectral resolution. Each of the 2048 spectral points is mapped to the model dimension via a local 1D convolution (kernel size 15, stride 1), followed by layer normalization and wavenumber-aware positional encoding that injects the physical frequency axis ($\text{cm}^{-1}$) into the representation.

Two special tokens are prepended:
- **[CLS]:** Aggregates global sequence information for downstream tasks
- **[DOMAIN]:** Learned embedding indicating the spectral modality (IR, Raman, NIR, or unknown)

This yields a sequence of 2050 tokens at dimension $d_\text{model} = 256$.

### Stage 2: D-LinOSS Backbone

The backbone uses 4 layers of **Damped Linear Oscillatory State-Space** models — a physics-aligned alternative to Mamba or standard S4. Each layer models 128 damped harmonic oscillators via IMEX symplectic discretization, providing an inductive bias that naturally matches the vibrational dynamics giving rise to spectral features.

The oscillator parameters (natural frequencies $\omega_i$ and damping coefficients $\gamma_i$) are learned during training. A critical engineering detail: the CFL stability ratio $\alpha = \Delta t^2 \omega^2 / S$ must be clamped below 2.0 to prevent eigenvalue escape from the unit circle during the 2048-step recurrence. Without this constraint, training diverges around step 1000–1400 as learned frequencies grow.

The entire D-LinOSS computation runs in float32 even under mixed-precision training, because the recurrence accumulates values reaching $\pm 200\text{K}$ that overflow float16/bfloat16 range.

### Stage 3: Mixture of Experts

Four expert FFN networks with top-$k=2$ sparse gating route tokens to modality-specialized subnetworks. A load-balancing auxiliary loss prevents expert collapse. Optional KAN (Kolmogorov-Arnold Network) activations in the experts provide interpretable activation shapes.

### Stage 4: Transformer Encoder

Two global self-attention blocks with 8 heads and $d_\text{ff} = 1024$ provide cross-position reasoning after the efficient O(n) backbone. This hybrid design captures both local spectral dependencies (D-LinOSS) and global compositional patterns (attention).

### Stage 5: VIB Disentanglement

The CLS token representation is split into:
- $z_\text{chem} \in \mathbb{R}^{128}$: chemistry-invariant, KL-regularized toward $\mathcal{N}(0, I)$
- $z_\text{inst} \in \mathbb{R}^{64}$: instrument-specific, designed to be discardable at transfer time

A **gradient reversal layer** ensures $z_\text{chem}$ cannot encode instrument identity: an adversarial classifier predicts the instrument from $z_\text{chem}$, but gradients are negated before reaching the encoder — training the encoder to actively remove instrument information from $z_\text{chem}$.

## Pretraining

### Dataset

Spektron is pretrained on **222K spectra from QM9S** — computed IR and Raman spectra for molecules in the QM9 dataset, each resampled to 2048 points covering 400–4000 $\text{cm}^{-1}$.

### Multi-Task Objectives

Seven concurrent loss functions provide complementary training signals:

1. **Masked Spectrum Reconstruction (MSRP):** 20% of spectral points masked in contiguous 3-point blocks, reconstructed from surrounding context. A learnable `mask_token` parameter replaces masked positions in the embedding space before the backbone — this is essential to prevent the model from degenerating to a near-identity mapping.

2. **BYOL Contrastive:** Augmented views of the same spectrum should produce similar $z_\text{chem}$ representations.

3. **Denoising:** Reconstruct clean spectrum from inputs corrupted with Gaussian noise ($\sigma = 0.01$), baseline drift, and wavelength shifts.

4. **Physics-Informed:** Enforce Beer-Lambert linearity, spectral smoothness, non-negativity, and peak symmetry on reconstructed spectra.

5. **Optimal Transport (Sinkhorn):** Minimize Wasserstein distance between latent distributions across instruments. Entropic regularization set to 1.0 (standard values like 0.05 cause numerical underflow for 128-dim embeddings).

6. **VIB:** KL divergence regularization on both $z_\text{chem}$ and $z_\text{inst}$, plus adversarial instrument classification with gradient reversal.

7. **MoE Balance:** Load-balancing loss across experts.

Loss weights: $1.0 : 0.3 : 0.2 : 0.1 : 0.1 : 0.15 : 0.01$.

### Training Configuration

| Parameter | Value |
|-----------|-------|
| Hardware | 2x RTX 5060 Ti (16GB each) |
| Batch size | 16 (8/GPU) × 4 grad accum = 64 effective |
| Optimizer | AdamW (lr=3e-4, wd=0.01) |
| Schedule | Linear warmup 1K steps → cosine decay |
| Max steps | 50,000 |
| Precision | bfloat16 AMP (LinOSS blocks in float32) |
| Throughput | ~39 samples/sec |

### Critical Implementation Details

Several subtle issues required careful engineering:

- **Mask before encode:** The mask must be applied in embedding space before the backbone. Passing unmasked spectra through the encoder and only using the mask for loss selection allows the model to learn a trivial identity mapping.

- **Gradient accumulation logging:** With $k$-step gradient accumulation, logging/validation/checkpointing must only occur on the actual optimizer step, not on every sub-step. Otherwise, metrics are logged $k\times$ too frequently and validation runs $k\times$ too often.

- **Step 0 guard:** All periodic actions (log every $N$, validate every $M$) must check `step > 0`, since $0 \bmod N = 0$ for any $N$.

- **Physics loss target:** Physics-informed losses (smoothness, non-negativity) must be applied to the model's reconstruction output, not the ground truth target — otherwise the gradient is zero and the loss has no training effect.

## Experiments

### E1: Architecture Benchmark

All five architectures are param-matched at ~2M backbone parameters and evaluated on masked spectral reconstruction (QM9S, 130K molecules, 2048 points). 3 seeds per architecture, reporting mean $\pm$ std for validation loss, training time, and peak GPU memory.

| Architecture | Backbone Params | Key Properties |
|-------------|:-:|---|
| D-LinOSS | 2.1M | 2nd-order oscillatory, O(n), bidirectional |
| Mamba | 1.8M | 1st-order selective SSM, O(n) |
| Transformer | 2.1M | Self-attention, O(n²) |
| 1D CNN | 2.1M | Local convolutions, FIR filters |
| S4D (ablation) | 1.1M | Diagonal SSM, no oscillatory structure |

### E2: Cross-Spectral Prediction

The novel contribution. Given an IR spectrum, predict the corresponding Raman spectrum (and vice versa). 99.93% of QM9 molecules are non-centrosymmetric, so mutual exclusion barely applies and both spectra are largely redundant but not identical. Metrics: spectral MSE, cosine similarity, peak-position recall, peak intensity correlation, and spectral information divergence (SID). Includes identity-copy baseline.

### E3: Transfer Function Analysis

Unique to SSMs: each D-LinOSS oscillator implements a 2nd-order IIR bandpass filter with transfer function:

$$H_p(z) = \frac{\Delta t^2 \cdot b_p \cdot z}{(1 + \Delta t \cdot g_p) z^2 - (2 + \Delta t \cdot g_p - \Delta t^2 \cdot a_p) z + 1}$$

We compute $|H(e^{j\omega})|$ for all oscillators across all layers, generating filter bank heatmaps, pole-zero plots, and per-layer frequency coverage. Statistical comparison between trained and random (untrained) models reveals whether training produces systematic spectral specialization.

### E4: Calibration Transfer

Fine-tune pretrained architectures on Corn (80 $\times$ 3 instruments $\times$ 700 NIR channels) with varying transfer sample budgets (5, 10, 20, 30, 50). Compare against PDS, SBC, DS, CCA, di-PLS classical baselines. Honest about the DFT mid-IR $\rightarrow$ experimental NIR domain gap — a negative result here is fine if framed properly.

## Related

- **Project:** [Spektron](/projects/spektron) — the implementation of this architecture
- **Theory:** [Spectral Identifiability](/research/spectral-identifiability) — the information-theoretic framework motivating the VIB design and dual-modality input
- **Blog:** [The Spectral Inverse Problem](/blog/spectral-inverse-problem) — accessible overview connecting group theory to the model architecture
- **Blog:** [Masked Pretraining for Scientific Spectra](/blog/masked-pretraining-scientific-spectra) — lessons learned from the masking strategy and common pitfalls
- **Blog:** [State-Space Models for Spectroscopy](/blog/state-space-models-for-spectroscopy) — why oscillatory SSMs match spectral physics
- **Preprocessing:** [SpectraKit](/projects/spectrakit) — the spectral preprocessing library used in Spektron's data pipeline
